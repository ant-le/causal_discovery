# @package trainer

lr: 0.001
weight_decay: 1e-4
accumulate_grad_batches: 1
max_steps: 30
log_every_n_steps: 1
val_check_interval: 10
checkpoint_every_n_steps: 0
amp: false
grad_clip_norm: 1.0
scheduler: cosine
scheduler_t_max: 30
scheduler_eta_min: 0.0
